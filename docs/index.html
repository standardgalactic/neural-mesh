<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
body {
    font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
    width: 980px;
}
h1 {
    font-weight:300;
    line-height: 1.15em;
}
h2 {
    font-size: 1.75em;
}
a:link,a:visited {
    color: #1367a7;
    text-decoration: none;
}
a:hover {
    color: #208799;
}
h1, h2, h3 {
    text-align: center;
}
h1 {
    font-size: 40px;
    font-weight: 500;
}
h2 {
    font-weight: 400;
    margin: 16px 0px 4px 0px;
}
.paper-title {
    padding: 16px 0px 16px 0px;
}
section {
    margin: 32px 0px 32px 0px;
    text-align: justify;
    clear: both;
}
.col-6 {
     width: 16.6%;
     float: left;
}
.col-5 {
     width: 20%;
     float: left;
}
.col-4 {
     width: 25%;
     float: left;
}
.col-3 {
     width: 33%;
     float: left;
}
.col-2 {
     width: 50%;
     float: left;
}
.row, .author-row, .affil-row {
     overflow: auto;
}
.author-row, .affil-row {
    font-size: 20px;
}
.row {
    margin: 16px 0px 16px 0px;
}
.authors {
    font-size: 18px;
}
.affil-row {
    margin-top: 16px;
}
.teaser {
    max-width: 100%;
}
.text-center {
    text-align: center;
}
.screenshot {
    width: 196px;
    border: 1px solid #ddd;
}
.screenshot-el {
    margin-bottom: 16px;
}
hr {
    height: 1px;
    border: 0;
    border-top: 1px solid #ddd;
    margin: 0;
}
.material-icons {
    vertical-align: -6px;
}
p {
    line-height: 1.25em;
}
.caption {
    font-size: 16px;
    /*font-style: italic;*/
    color: #666;
    text-align: left;
    margin-top: 8px;
    margin-bottom: 8px;
}
video {
    display: block;
    margin: auto;
}
figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
#bibtex pre {
    font-size: 14px;
    background-color: #eee;
    padding: 16px;
}
.blue {
    color: #2c82c9;
    font-weight: bold;
}
.orange {
    color: #d35400;
    font-weight: bold;
}
.flex-row {
    display: flex;
    flex-flow: row wrap;
    justify-content: space-around;
    padding: 0;
    margin: 0;
    list-style: none;
}
.paper-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;

  background-color: #1367a7;
  color: #ecf0f1 !important;
  font-size: 20px;
  width: 100px;
  font-weight: 600;
}
.supp-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;

  background-color: #1367a7;
  color: #ecf0f1 !important;
  font-size: 20px;
  width: 150px;
  font-weight: 600;
}
.paper-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}
.paper-btn:hover {
    opacity: 0.85;
}
.container {
    margin-left: auto;
    margin-right: auto;
    padding-left: 16px;
    padding-right: 16px;
}
.venue {
    color: #1367a7;
}
.topnav {
  overflow: hidden;
  background-color: #EEEEEE;
}
.topnav a {
  float: left;
  color: black;
  text-align: center;
  padding: 14px 16px;
  text-decoration: none;
  font-size: 16px;
}
</style>


<div class="topnav" id="myTopnav">
  <a href="https://www.cs.jhu.edu"><img height="21px" src="assets/jhu.png"></a>
  <a href="https://ccvl.jhu.edu" ><strong>Johns Hopkins University</strong></a>
</div>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3R5HPSX0G1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3R5HPSX0G1');
</script>
<!-- End : Google Analytics Code -->

<script type="text/javascript" src="../js/hidebib.js"></script>
<link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>

<head>
    <title>Neural Mesh Models for 3D Reasoning</title>
    <meta property="og:description" content="Neural Mesh Models for 3D Reasoning"/>
    <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">

</head>


 <body>
<div class="container">
    <div class="paper-title">
      <h1>Neural Mesh Models for 3D Reasoning</h1>
    </div>

    <div id="authors">
        <div class="author-row">
            <div class="col-3 text-center"><a href="https://wufeim.github.io">Wufei Ma</a><sup>1</sup></div>
            <div class="col-3 text-center"><a href="https://arturjssln.github.io">Artur Jesslen</a><sup>2</sup></div>
            <div class="col-3 text-center"><a href="https://github.com/Angtian">Angtian Wang</a><sup>1</sup></div>
            <div class="col-2 text-center"><a href="https://www.cs.jhu.edu/~ayuille/">Alan Yuille</a><sup>1</sup></div>
            <div class="col-2 text-center"><a href="https://generativevision.mpi-inf.mpg.de">Adam Kortylewski</a><sup>2,3</sup></div>
        </div>

        <div class="affil-row">
            <div class="col-3 text-center"><sup>1</sup>Johns Hopkins University</a></div>
            <div class="col-3 text-center"><sup>2</sup>University of Freiburg</div>
            <div class="col-3 text-center"><sup>3</sup>Max-Planck-Institute of Informatics</div>
        </div>

        <!-- <div class="affil-row">
            <div class="venue text-center"><b>NeurIPS 2022</b></div>
        </div> -->

        <div style="clear: both">
            <div class="paper-btn-parent">
            <a class="supp-btn" href="#paper">
                <span class="material-icons"> description </span>
                 Paper
            </a>
            </a>
            <a class="supp-btn" href="#bibtex">
                <span class="material-icons"> description </span>
                  BibTeX
            </a>
            <a class="supp-btn" href="https://github.com/wufeim/NeMo">
                <span class="material-icons"> description </span>
                  Code
            </a>
        </div></div>
    </div>

    <section id="teaser">
        <figure style="width: 100%;">
            <a href="assets/teaser.png">
                <img width="80%" src="assets/teaser.png" style="display: block; margin-left: auto; margin-right: auto;">
            </a>
            <p class="caption" style="margin-bottom: 1px;  text-align: justify">
                We propose neural mesh models (NeMo) that learns a generative model of nueral feature activiations at each vertex on a dense 3D mesh. Using differentiable rendering we solve 3D objects by minimizing the reconstruction error between a predicted feature representation and a representation rendered from an estimated 3D scene.
            </p>
        </figure>
        <br>
    </section>

    <section id="abstract"/>
        <h2>Abstract</h2>
        <hr>
        <p>
            Our work is built on feature-level render-and-compare methods, which approximate the analysis-by-synthesis approaches in computer vision. Analysis-by-synthesis approaches have several advantages over purely discriminative methods as it enables efficient learning and largely enhances robustness in image classification, pose estimation, and scene understanding, as well as when objects are viewed from unseen 3D poses. We propose neural mesh models (NeMo) that learns a generative model of nueral feature activiations at each vertex on a dense 3D mesh. Using differentiable rendering we solve 3D objects by minimizing the reconstruction error between a predicted feature representation and a representation rendered from an estimated 3D scene. This codebase implements <a href="#paper">multiple previous works</a> on neural mesh methods, which targets various tasks (e.g., 3D/6D pose estimation and 3D-aware image classification) in different settings (i.e., few-shot and fully-supervised).
        </p>
    </section>

    <section id="results">
        <h2>Features</h2>
        <hr>

        <figure style="width: 100%;">
            <a href="assets/pose3d.gif">
                <img width="100%" src="assets/pose3d.gif" style="display: block; margin-left: auto; margin-right: auto;">
            </a>
            <p class="caption" style="margin-bottom: 1px;  text-align: justify">
                3D pose estimation.
            </p>
        </figure>

    </section>

    <section id="results">
        <h2>Documentation</h2>
        <hr>
        <p>
            See <a href="documentation.html">documentation.html</a>.
        </p>
    </section>

    <section id="paper">
        <h2>Paper</h2>
        <hr>
        <div class="flex-row">
            <div style="box-sizing: border-box; padding: 16px; margin: auto;">
                <a href="assets/nemo.pdf"><img class="screenshot" src="assets/nemo.jpg"></a>
            </div>
            <div style="width: 50%">
                <p><b>NeMo: Neural Mesh Models of Contrastive Features for Robust 3D Pose Estimation</b></p>
                <p>Angtian Wang, Adam Kortylewski, Alan Yuille</p>
                <p>ICLR 2021</p>
                <div><span class="material-icons"> description </span><a href="assets/nemo.pdf"> PDF</a></div>
                <div><span class="material-icons"> insert_comment </span><a href="assets/nemo_bib.txt"> BibTeX</a></div>
            </div>
        </div>
        <div class="flex-row">
            <div style="box-sizing: border-box; padding: 16px; margin: auto;">
                <a href="assets/nemo6d.pdf"><img class="screenshot" src="assets/nemo6d.jpg"></a>
            </div>
            <div style="width: 50%">
                <p><b>Robust Category-Level 6D Pose Estimation with Coarse-to-Fine Rendering of Neural Features</b></p>
                <p>Wufei Ma, Angtian Wang, Adam Kortylewski, Alan Yuille</p>
                <p>ECCV 2022</p>
                <div><span class="material-icons"> description </span><a href="assets/nemo6d.pdf"> PDF</a></div>
                <div><span class="material-icons"> insert_comment </span><a href="assets/nemo6d_bib.txt"> BibTeX</a></div>
            </div>
        </div>
    </section>


    <section id="bibtex">
        <h2>Citation</h2>
        <hr>

        <pre><code>@inproceedings{wang2021nemo,
    title={NeMo: Neural Mesh Models of Contrastive Features for Robust 3D Pose Estimation},
    author={Angtian Wang and Adam Kortylewski and Alan Yuille},
    booktitle={International Conference on Learning Representations},
    year={2021},
    url={https://openreview.net/forum?id=pmj131uIL9H}
}
@software{nemo_code_2022,
    title={Neural Mesh Models for 3D Reasoning},
    author={Ma, Wufei and Jesslen, Artur and Wang, Angtian},
    month={12},
    year={2022},
    url={https://github.com/wufeim/NeMo},
    version={1.0.0}
}
</code></pre>

    </section>

        <section id="bibtex">
        <h2>Further Information</h2>
        <hr>
        <p>
            This repo builds upon several previous works:
            <ul>
                <li><a href="https://openreview.net/forum?id=pmj131uIL9H">NeMo: Neural Mesh Models of Contrastive Features for Robust 3D Pose Estimation (ICLR 2021)</a></li>
                <li><a href="https://link.springer.com/chapter/10.1007/978-3-031-20077-9_29">Robust Category-Level 6D Pose Estimation with Coarse-to-Fine Rendering of Neural Features (ECCV 2022)</a></li>
            </ul>

        </p>
        <p>

             Please also consider citing these papers if you follow our work.
        </p>
        <pre><code>@inproceedings{wang2021nemo,
    title={NeMo: Neural Mesh Models of Contrastive Features for Robust 3D Pose Estimation},
    author={Angtian Wang and Adam Kortylewski and Alan Yuille},
    booktitle={International Conference on Learning Representations},
    year={2021},
    url={https://openreview.net/forum?id=pmj131uIL9H}
}</code></pre>

    </section>

<br />

</div>
</body>
</html>
